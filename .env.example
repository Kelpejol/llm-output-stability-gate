# ==============================================
# UQLM-Guard - Environment Configuration
# ==============================================

# OpenAI API Configuration (REQUIRED)
OPENAI_API_KEY=your_openai_api_key_here
# Get your key from: https://platform.openai.com/api-keys

# Model Configuration
OPENAI_MODEL=gpt-4o-mini
# Options: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Note: gpt-4o provides better consistency but costs more

OPENAI_TEMPERATURE=0.7
# Range: 0.0 to 2.0
# Higher = more diverse responses (better for uncertainty detection)
# Lower = more deterministic responses

# UQLM Configuration
DEFAULT_NUM_SAMPLES=5
# Number of responses to generate per analysis
# Range: 2-10 (5 is optimal for most cases)
# Higher = more accurate but slower and more expensive

DEFAULT_MIN_CONFIDENCE=0.6
# Confidence threshold for acceptance
# Range: 0.0-1.0
# 0.8+ = High confidence
# 0.6-0.8 = Medium confidence
# <0.6 = Low confidence

# Logging
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# Optional: Cost Tracking
TRACK_API_COSTS=true
# Set to false to disable cost tracking

# Optional: Cache Results
ENABLE_CACHE=true
# Cache analysis results to avoid redundant API calls
CACHE_TTL_HOURS=24

# Optional: Rate Limiting
RATE_LIMIT_RPM=60
# Requests per minute (to avoid API limits)