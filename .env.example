# ==============================================
# LLM Output Stability Gate - Environment Config
# ==============================================

# OpenAI API Configuration (REQUIRED)
OPENAI_API_KEY=your_openai_api_key_here
# Get your key from: https://platform.openai.com/api-keys

# OpenAI Model Configuration
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000

# Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=4

# UQLM Configuration
DEFAULT_NUM_SAMPLES=5
DEFAULT_MIN_CONFIDENCE=0.6

# Evaluation Limits
MIN_NUM_SAMPLES=2
MAX_NUM_SAMPLES=10
MIN_CONFIDENCE_THRESHOLD=0.0
MAX_CONFIDENCE_THRESHOLD=1.0

# Logging Configuration
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# API Rate Limiting (optional)
RATE_LIMIT_ENABLED=false
RATE_LIMIT_PER_MINUTE=30
RATE_LIMIT_BURST=5

# Timeout Settings
EVALUATION_TIMEOUT_SECONDS=60
API_REQUEST_TIMEOUT=30

# CORS Settings
CORS_ORIGINS=*
# For production: https://yourdomain.com

# Monitoring (optional)
ENABLE_METRICS=true
METRICS_PORT=9090

# Cost Tracking (optional)
TRACK_API_COSTS=true
COST_ALERT_THRESHOLD=10.00
